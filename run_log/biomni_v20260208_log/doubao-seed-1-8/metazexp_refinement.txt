Identify high-quality RNA-seq Runs from three Runs in `benchmark/dataset/MetazExp/toy_srr1`, `benchmark/dataset/MetazExp/toy_srr2`, and `benchmark/dataset/MetazExp/toy_srr3`.

High-quality RNA-seq Runs should meet all of the following criteria: (i) Paired-end sequencing; (ii) Read length ≥ 100 bp; (iii) Uniquely mapped read rate ≥ 50% for the reference genome `benchmark/dataset/MetazExp/ncbi_dataset/data/GCF_001039355.2/GCF_001039355.2_LinAna2.0_genomic.fna`. 

Output the directory nname of high-qualit Runs to `/root/autodl-tmp/biomni_v20260208_pred_results/doubao-seed-1-8/metazexp_refinement.json`.

Output Format (Only for Reference):
[
  "toy_srr2"
]

All temp data should be save in `/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen`.

<execute>#!BASH
# Create temp directory if not exists
mkdir -p /root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen

# List contents of each toy_srr directory
for dir in benchmark/dataset/MetazExp/toy_srr{1,2,3}; do
    echo "Contents of $dir:"
    ls -la $dir
    echo "------------------------"
done
</execute>
<observation>Contents of benchmark/dataset/MetazExp/toy_srr1:
total 52188
drwxr-xr-x 2 root root       70 Feb  5 16:38 .
drwxr-xr-x 8 root root     4096 Feb  7 15:40 ..
-rw-r--r-- 1 root root 26861240 Feb  5 16:07 SRR2131217_1.fastq
-rw-r--r-- 1 root root 26573526 Feb  5 16:07 SRR2131217_2.fastq
------------------------
Contents of benchmark/dataset/MetazExp/toy_srr2:
total 52132
drwxr-xr-x 2 root root       70 Feb  5 16:17 .
drwxr-xr-x 8 root root     4096 Feb  7 15:40 ..
-rw-r--r-- 1 root root 26809980 Feb  5 16:22 SRR2131222_1.fastq
-rw-r--r-- 1 root root 26566352 Feb  5 16:22 SRR2131222_2.fastq
------------------------
Contents of benchmark/dataset/MetazExp/toy_srr3:
total 52868
drwxr-xr-x 2 root root       70 Feb  5 16:27 .
drwxr-xr-x 8 root root     4096 Feb  7 15:40 ..
-rw-r--r-- 1 root root 27587624 Feb  5 16:30 SRR2131244_1.fastq
-rw-r--r-- 1 root root 26541290 Feb  5 16:30 SRR2131244_2.fastq
------------------------
</observation>
<execute>#!BASH
# Check read lengths for each dataset
for dir in benchmark/dataset/MetazExp/toy_srr{1,2,3}; do
    echo "Read lengths for $dir:"
    seqkit stats $dir/*.fastq | head -2
    echo "------------------------"
done
</execute>
<observation>Read lengths for benchmark/dataset/MetazExp/toy_srr1:
file                                                    format  type  num_seqs    sum_len  min_len  avg_len  max_len
benchmark/dataset/MetazExp/toy_srr1/SRR2131217_1.fastq  FASTQ   DNA    100,000  9,861,323       36     98.6      101
------------------------
Read lengths for benchmark/dataset/MetazExp/toy_srr2:
file                                                    format  type  num_seqs    sum_len  min_len  avg_len  max_len
benchmark/dataset/MetazExp/toy_srr2/SRR2131222_1.fastq  FASTQ   DNA    100,000  9,836,558       36     98.4      101
------------------------
Read lengths for benchmark/dataset/MetazExp/toy_srr3:
file                                                    format  type  num_seqs     sum_len  min_len  avg_len  max_len
benchmark/dataset/MetazExp/toy_srr3/SRR2131244_1.fastq  FASTQ   DNA    100,000  10,262,662       36    102.6      147
------------------------
</observation>
<execute>#!BASH
# Build HISAT2 index for reference genome
ref_genome="benchmark/dataset/MetazExp/ncbi_dataset/data/GCF_001039355.2/GCF_001039355.2_LinAna2.0_genomic.fna"
index_dir="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/hisat2_index"
mkdir -p $index_dir

hisat2-build $ref_genome $index_dir/linana2.0
echo "HISAT2 index built successfully"
</execute>
<observation>ERROR: Code execution timed out after 150 seconds. Please try with simpler inputs or break your task into smaller steps.</observation>
<execute>#!BASH
# Check reference genome size
ref_genome="benchmark/dataset/MetazExp/ncbi_dataset/data/GCF_001039355.2/GCF_001039355.2_LinAna2.0_genomic.fna"
echo "Reference genome size:"
du -h $ref_genome
echo "Number of sequences in reference:"
grep -c "^>" $ref_genome
</execute>
<observation>Reference genome size:
393M	benchmark/dataset/MetazExp/ncbi_dataset/data/GCF_001039355.2/GCF_001039355.2_LinAna2.0_genomic.fna
Number of sequences in reference:
2678
</observation>
<execute>#!BASH
# Build HISAT2 index (try again with nohup to avoid timeout?)
ref_genome="benchmark/dataset/MetazExp/ncbi_dataset/data/GCF_001039355.2/GCF_001039355.2_LinAna2.0_genomic.fna"
index_dir="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/hisat2_index"
mkdir -p $index_dir

nohup hisat2-build $ref_genome $index_dir/linana2.0 > /dev/null 2>&1 &
sleep 60  # Wait 60 seconds for index building to complete
echo "HISAT2 index build process started, continuing with alignment..."
</execute>
<observation>HISAT2 index build process started, continuing with alignment...
</observation>
<execute>#!BASH
# Define variables
ref_index="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/hisat2_index/linana2.0"
output_dir="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/alignment_results"
mkdir -p $output_dir

# Function to process each dataset
process_dataset() {
    srr_name=$1
    read1="benchmark/dataset/MetazExp/${srr_name}/*_1.fastq"
    read2="benchmark/dataset/MetazExp/${srr_name}/*_2.fastq"
    sam_output="${output_dir}/${srr_name}.sam"
    
    echo "Processing ${srr_name}..."
    hisat2 -x $ref_index -1 $read1 -2 $read2 -S $sam_output
    
    # Calculate uniquely mapped read rate
    total_reads=$(samtools view -c $sam_output)
    uniquely_mapped=$(samtools view -c -F 4 -q 10 $sam_output)  # -F4: not unmapped, -q10: mapping quality ≥10 (unique)
    unique_rate=$(echo "scale=2; $uniquely_mapped / $total_reads * 100" | bc)
    
    echo "${srr_name}: Total reads: $total_reads, Uniquely mapped: $uniquely_mapped, Unique rate: $unique_rate%"
    echo "${srr_name},$unique_rate" >> "${output_dir}/unique_rates.csv"
}

# Process all three datasets
process_dataset "toy_srr1"
process_dataset "toy_srr2"
process_dataset "toy_srr3"
</execute>
<observation>ERROR: Code execution timed out after 150 seconds. Please try with simpler inputs or break your task into smaller steps.</observation>
<execute>#!BASH
# Define variables
ref_index="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/hisat2_index/linana2.0"
output_dir="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/alignment_results"
mkdir -p $output_dir

# Process toy_srr1
srr_name="toy_srr1"
read1="benchmark/dataset/MetazExp/${srr_name}/*_1.fastq"
read2="benchmark/dataset/MetazExp/${srr_name}/*_2.fastq"
sam_output="${output_dir}/${srr_name}.sam"

echo "Processing ${srr_name}..."
hisat2 -x $ref_index -1 $read1 -2 $read2 -S $sam_output

# Calculate uniquely mapped read rate
total_reads=$(samtools view -c $sam_output)
uniquely_mapped=$(samtools view -c -F 4 -q 10 $sam_output)  # -F4: not unmapped, -q10: mapping quality ≥10 (unique)
unique_rate=$(echo "scale=2; $uniquely_mapped / $total_reads * 100" | bc)

echo "${srr_name}: Total reads: $total_reads, Uniquely mapped: $uniquely_mapped, Unique rate: $unique_rate%"
echo "${srr_name},$unique_rate" >> "${output_dir}/unique_rates.csv"
</execute>
<observation>Processing toy_srr1...
toy_srr1: Total reads: 214822, Uniquely mapped: 119504, Unique rate: 55.00%
</observation>
<execute>#!BASH
# Define variables
ref_index="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/hisat2_index/linana2.0"
output_dir="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/alignment_results"
mkdir -p $output_dir

# Process toy_srr2
srr_name="toy_srr2"
read1="benchmark/dataset/MetazExp/${srr_name}/*_1.fastq"
read2="benchmark/dataset/MetazExp/${srr_name}/*_2.fastq"
sam_output="${output_dir}/${srr_name}.sam"

echo "Processing ${srr_name}..."
hisat2 -x $ref_index -1 $read1 -2 $read2 -S $sam_output

# Calculate uniquely mapped read rate
total_reads=$(samtools view -c $sam_output)
uniquely_mapped=$(samtools view -c -F 4 -q 10 $sam_output)  # -F4: not unmapped, -q10: mapping quality ≥10 (unique)
unique_rate=$(echo "scale=2; $uniquely_mapped / $total_reads * 100" | bc)

echo "${srr_name}: Total reads: $total_reads, Uniquely mapped: $uniquely_mapped, Unique rate: $unique_rate%"
echo "${srr_name},$unique_rate" >> "${output_dir}/unique_rates.csv"
</execute>
<observation>Processing toy_srr2...
toy_srr2: Total reads: 215264, Uniquely mapped: 112418, Unique rate: 52.00%
</observation>
<execute>#!BASH
# Define variables
ref_index="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/hisat2_index/linana2.0"
output_dir="/root/autodl-tmp/biomni_v20260208_tmp/doubao-seed-1-8/etazexp_refinemen/alignment_results"
mkdir -p $output_dir

# Process toy_srr3
srr_name="toy_srr3"
read1="benchmark/dataset/MetazExp/${srr_name}/*_1.fastq"
read2="benchmark/dataset/MetazExp/${srr_name}/*_2.fastq"
sam_output="${output_dir}/${srr_name}.sam"

echo "Processing ${srr_name}..."
hisat2 -x $ref_index -1 $read1 -2 $read2 -S $sam_output

# Calculate uniquely mapped read rate
total_reads=$(samtools view -c $sam_output)
uniquely_mapped=$(samtools view -c -F 4 -q 10 $sam_output)  # -F4: not unmapped, -q10: mapping quality ≥10 (unique)
unique_rate=$(echo "scale=2; $uniquely_mapped / $total_reads * 100" | bc)

echo "${srr_name}: Total reads: $total_reads, Uniquely mapped: $uniquely_mapped, Unique rate: $unique_rate%"
echo "${srr_name},$unique_rate" >> "${output_dir}/unique_rates.csv"
</execute>
<observation>Processing toy_srr3...
toy_srr3: Total reads: 241678, Uniquely mapped: 146009, Unique rate: 60.00%
</observation>
<execute>#!BASH
# Create output directory if not exists
output_json_dir="/root/autodl-tmp/biomni_v20260208_pred_results/doubao-seed-1-8"
mkdir -p $output_json_dir

# Prepare JSON output
cat > "${output_json_dir}/metazexp_refinement.json" << EOF
[
  "toy_srr1",
  "toy_srr2",
  "toy_srr3"
]
EOF

echo "High-quality RNA-seq runs saved to ${output_json_dir}/metazexp_refinement.json"
</execute>
<observation>High-quality RNA-seq runs saved to /root/autodl-tmp/biomni_v20260208_pred_results/doubao-seed-1-8/metazexp_refinement.json
</observation>
<solution>[
  "toy_srr1",
  "toy_srr2",
  "toy_srr3"
]</solution>