Identify the top 100 genes that most frequently exhibit Allele-Specific Methylation (ASM) across a population of samples. 

Given detected ASM sites across multiple biological samples `benchmark/dataset/ASMdb/mock/mock_asm_sites.csv` and genomic coordinates for all genes `benchmark/dataset/ASMdb/mock/mock_genes.csv`.

For each sample, quantified the number of ASM sites within each gene body and its $3~\mathrm{kb}$ upstream region. The frequency of genes covered by ASM was then aggregated across all samples. 

Finally, identified the top 100 genes with the highest ASM frequency, and save the result into a csv file `/root/autodl-tmp/biomni_v20260208_pred_results/deepseek-v3.2-fast/asmdb_annotate.csv`

Output example for reference:
gene_id,frequency
GENE_1,15
GENE_2,14
GENE_3,13
GENE_4,12
...

All intermediate code generated during execution, downloaded files, and temporary results must be stored in `/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate`

I'll start by making a plan to solve this task.

**Plan:**
1. [ ] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [ ] Load the data into appropriate data structures
3. [ ] Define gene regions: gene body + 3kb upstream
4. [ ] For each sample, count ASM sites within each gene region
5. [ ] Aggregate counts across all samples to get frequency per gene
6. [ ] Sort genes by frequency and select top 100
7. [ ] Save results to the specified output file
8. [ ] Ensure all intermediate files are stored in the specified temporary directory

Let me start by examining the data structure.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# First, let's check if the input files exist
asm_sites_path = "benchmark/dataset/ASMdb/mock/mock_asm_sites.csv"
genes_path = "benchmark/dataset/ASMdb/mock/mock_genes.csv"

print(f"Checking if files exist:")
print(f"ASM sites: {asm_sites_path} - {os.path.exists(asm_sites_path)}")
print(f"Genes: {genes_path} - {os.path.exists(genes_path)}")

# Create temporary directory if it doesn't exist
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"
os.makedirs(tmp_dir, exist_ok=True)
print(f"Created temporary directory: {tmp_dir}")
</execute>
<observation>Checking if files exist:
ASM sites: benchmark/dataset/ASMdb/mock/mock_asm_sites.csv - True
Genes: benchmark/dataset/ASMdb/mock/mock_genes.csv - True
Created temporary directory: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate
</observation>
Good, the files exist. Now let me examine the structure of both files to understand the data.

<execute>
# Load and examine the ASM sites file
print("Loading ASM sites file...")
asm_sites = pd.read_csv(asm_sites_path)
print(f"ASM sites shape: {asm_sites.shape}")
print("\nFirst few rows of ASM sites:")
print(asm_sites.head())
print("\nColumns in ASM sites:")
print(asm_sites.columns.tolist())
print("\nSample IDs in ASM sites:")
print(asm_sites['sample_id'].unique()[:10] if 'sample_id' in asm_sites.columns else "No sample_id column found")
print(f"Number of unique samples: {asm_sites['sample_id'].nunique() if 'sample_id' in asm_sites.columns else 'N/A'}")
</execute>
<observation>NameError("name 'pd' is not defined")</observation>
I need to import pandas first.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# Load and examine the ASM sites file
print("Loading ASM sites file...")
asm_sites = pd.read_csv(asm_sites_path)
print(f"ASM sites shape: {asm_sites.shape}")
print("\nFirst few rows of ASM sites:")
print(asm_sites.head())
print("\nColumns in ASM sites:")
print(asm_sites.columns.tolist())
print("\nSample IDs in ASM sites:")
print(asm_sites['sample_id'].unique()[:10] if 'sample_id' in asm_sites.columns else "No sample_id column found")
print(f"Number of unique samples: {asm_sites['sample_id'].nunique() if 'sample_id' in asm_sites.columns else 'N/A'}")
</execute>
<observation>NameError("name 'asm_sites_path' is not defined")</observation>
I need to redefine the paths.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# Define paths
asm_sites_path = "benchmark/dataset/ASMdb/mock/mock_asm_sites.csv"
genes_path = "benchmark/dataset/ASMdb/mock/mock_genes.csv"

# Load and examine the ASM sites file
print("Loading ASM sites file...")
asm_sites = pd.read_csv(asm_sites_path)
print(f"ASM sites shape: {asm_sites.shape}")
print("\nFirst few rows of ASM sites:")
print(asm_sites.head())
print("\nColumns in ASM sites:")
print(asm_sites.columns.tolist())
print("\nSample IDs in ASM sites:")
print(asm_sites['sample_id'].unique()[:10] if 'sample_id' in asm_sites.columns else "No sample_id column found")
print(f"Number of unique samples: {asm_sites['sample_id'].nunique() if 'sample_id' in asm_sites.columns else 'N/A'}")
</execute>
<observation>Loading ASM sites file...
ASM sites shape: (5000, 4)

First few rows of ASM sites:
   sample_id chrom      pos  asm_score
0  Sample_12  chr2  3690097      0.189
1  Sample_07  chr1  1182432      0.211
2  Sample_15  chr3  2863689      0.267
3  Sample_10  chr3  7342832      0.149
4  Sample_19  chr5  3948477      0.364

Columns in ASM sites:
['sample_id', 'chrom', 'pos', 'asm_score']

Sample IDs in ASM sites:
['Sample_12' 'Sample_07' 'Sample_15' 'Sample_10' 'Sample_19' 'Sample_14'
 'Sample_03' 'Sample_08' 'Sample_17' 'Sample_13']
Number of unique samples: 20
</observation>
Now let me examine the genes file.

<execute>
# Load and examine the genes file
print("Loading genes file...")
genes = pd.read_csv(genes_path)
print(f"Genes shape: {genes.shape}")
print("\nFirst few rows of genes:")
print(genes.head())
print("\nColumns in genes:")
print(genes.columns.tolist())
print("\nGene ID column check:")
print(f"Gene ID column exists: {'gene_id' in genes.columns}")
if 'gene_id' in genes.columns:
    print(f"Number of unique genes: {genes['gene_id'].nunique()}")
</execute>
<observation>NameError("name 'pd' is not defined")</observation>
I need to re-import pandas.

<execute>
import pandas as pd

# Load and examine the genes file
print("Loading genes file...")
genes = pd.read_csv(genes_path)
print(f"Genes shape: {genes.shape}")
print("\nFirst few rows of genes:")
print(genes.head())
print("\nColumns in genes:")
print(genes.columns.tolist())
print("\nGene ID column check:")
print(f"Gene ID column exists: {'gene_id' in genes.columns}")
if 'gene_id' in genes.columns:
    print(f"Number of unique genes: {genes['gene_id'].nunique()}")
</execute>
<observation>NameError("name 'genes_path' is not defined")</observation>
Let me define all variables again.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# Define paths
asm_sites_path = "benchmark/dataset/ASMdb/mock/mock_asm_sites.csv"
genes_path = "benchmark/dataset/ASMdb/mock/mock_genes.csv"

# Load and examine the genes file
print("Loading genes file...")
genes = pd.read_csv(genes_path)
print(f"Genes shape: {genes.shape}")
print("\nFirst few rows of genes:")
print(genes.head())
print("\nColumns in genes:")
print(genes.columns.tolist())
print("\nGene ID column check:")
print(f"Gene ID column exists: {'gene_id' in genes.columns}")
if 'gene_id' in genes.columns:
    print(f"Number of unique genes: {genes['gene_id'].nunique()}")
</execute>
<observation>Loading genes file...
Genes shape: (1000, 5)

First few rows of genes:
     gene_id chrom    start      end strand
0  GENE_0001  chr4  6433388  6439778      +
1  GENE_0002  chr5  2244489  2262339      +
2  GENE_0003  chr3  9534682  9550105      +
3  GENE_0004  chr4  9638519  9655542      +
4  GENE_0005  chr5  4991505  4994938      -

Columns in genes:
['gene_id', 'chrom', 'start', 'end', 'strand']

Gene ID column check:
Gene ID column exists: True
Number of unique genes: 1000
</observation>
Now I understand the data structure. Let me update my plan:

1. [✓] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [ ] Load the data into appropriate data structures
3. [ ] Define gene regions: gene body + 3kb upstream
4. [ ] For each sample, count ASM sites within each gene region
5. [ ] Aggregate counts across all samples to get frequency per gene
6. [ ] Sort genes by frequency and select top 100
7. [ ] Save results to the specified output file
8. [ ] Ensure all intermediate files are stored in the specified temporary directory

Now I need to implement step 2 and 3. First, I'll create gene regions with 3kb upstream. For genes on the '+' strand, upstream is before the start; for '-' strand, upstream is after the end.

<execute>
# Create gene regions with 3kb upstream
print("Creating gene regions with 3kb upstream...")

# Make a copy of genes dataframe
gene_regions = genes.copy()

# For + strand: upstream region is [start - 3000, start)
# For - strand: upstream region is [end, end + 3000)
# We'll create extended regions that include both gene body and upstream
gene_regions['region_start'] = gene_regions.apply(
    lambda row: row['start'] - 3000 if row['strand'] == '+' else row['start'], 
    axis=1
)
gene_regions['region_end'] = gene_regions.apply(
    lambda row: row['end'] if row['strand'] == '+' else row['end'] + 3000, 
    axis=1
)

# Ensure region_start is not negative (minimum 0)
gene_regions['region_start'] = gene_regions['region_start'].clip(lower=0)

print(f"Created gene regions for {len(gene_regions)} genes")
print("\nFirst few rows of gene regions:")
print(gene_regions[['gene_id', 'chrom', 'start', 'end', 'strand', 'region_start', 'region_end']].head())

# Save intermediate result
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"
gene_regions_path = os.path.join(tmp_dir, "gene_regions.csv")
gene_regions.to_csv(gene_regions_path, index=False)
print(f"\nSaved gene regions to: {gene_regions_path}")
</execute>
<observation>NameError("name 'genes' is not defined")</observation>
I need to reload the data.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# Define paths
asm_sites_path = "benchmark/dataset/ASMdb/mock/mock_asm_sites.csv"
genes_path = "benchmark/dataset/ASMdb/mock/mock_genes.csv"

# Load data
asm_sites = pd.read_csv(asm_sites_path)
genes = pd.read_csv(genes_path)

# Create gene regions with 3kb upstream
print("Creating gene regions with 3kb upstream...")

# Make a copy of genes dataframe
gene_regions = genes.copy()

# For + strand: upstream region is [start - 3000, start)
# For - strand: upstream region is [end, end + 3000)
# We'll create extended regions that include both gene body and upstream
gene_regions['region_start'] = gene_regions.apply(
    lambda row: row['start'] - 3000 if row['strand'] == '+' else row['start'], 
    axis=1
)
gene_regions['region_end'] = gene_regions.apply(
    lambda row: row['end'] if row['strand'] == '+' else row['end'] + 3000, 
    axis=1
)

# Ensure region_start is not negative (minimum 0)
gene_regions['region_start'] = gene_regions['region_start'].clip(lower=0)

print(f"Created gene regions for {len(gene_regions)} genes")
print("\nFirst few rows of gene regions:")
print(gene_regions[['gene_id', 'chrom', 'start', 'end', 'strand', 'region_start', 'region_end']].head())

# Save intermediate result
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"
os.makedirs(tmp_dir, exist_ok=True)
gene_regions_path = os.path.join(tmp_dir, "gene_regions.csv")
gene_regions.to_csv(gene_regions_path, index=False)
print(f"\nSaved gene regions to: {gene_regions_path}")
</execute>
<observation>Creating gene regions with 3kb upstream...
Created gene regions for 1000 genes

First few rows of gene regions:
     gene_id chrom    start      end strand  region_start  region_end
0  GENE_0001  chr4  6433388  6439778      +       6430388     6439778
1  GENE_0002  chr5  2244489  2262339      +       2241489     2262339
2  GENE_0003  chr3  9534682  9550105      +       9531682     9550105
3  GENE_0004  chr4  9638519  9655542      +       9635519     9655542
4  GENE_0005  chr5  4991505  4994938      -       4991505     4997938

Saved gene regions to: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/gene_regions.csv
</observation>
Good! Now I need to count ASM sites within each gene region for each sample. Let me update my plan:

1. [✓] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [✓] Load the data into appropriate data structures
3. [✓] Define gene regions: gene body + 3kb upstream
4. [ ] For each sample, count ASM sites within each gene region
5. [ ] Aggregate counts across all samples to get frequency per gene
6. [ ] Sort genes by frequency and select top 100
7. [ ] Save results to the specified output file
8. [ ] Ensure all intermediate files are stored in the specified temporary directory

Now I need to implement step 4. I'll create a function to check if an ASM site is within a gene region.

<execute>
# Function to count ASM sites in gene regions for each sample
print("Counting ASM sites in gene regions for each sample...")

# Get unique samples
unique_samples = asm_sites['sample_id'].unique()
print(f"Number of samples: {len(unique_samples)}")

# Initialize a dictionary to store counts
gene_counts = {}

# Process each sample
for sample in unique_samples:
    print(f"Processing sample: {sample}")
    
    # Get ASM sites for this sample
    sample_sites = asm_sites[asm_sites['sample_id'] == sample]
    
    # For each gene, count ASM sites within its region
    for _, gene_row in gene_regions.iterrows():
        gene_id = gene_row['gene_id']
        chrom = gene_row['chrom']
        region_start = gene_row['region_start']
        region_end = gene_row['region_end']
        
        # Filter ASM sites for this chromosome
        chrom_sites = sample_sites[sample_sites['chrom'] == chrom]
        
        # Count sites within region
        count = ((chrom_sites['pos'] >= region_start) & (chrom_sites['pos'] <= region_end)).sum()
        
        # Initialize gene in dictionary if not present
        if gene_id not in gene_counts:
            gene_counts[gene_id] = {}
        
        # Store count for this sample
        gene_counts[gene_id][sample] = count

print(f"Processed {len(unique_samples)} samples")
print(f"Counted ASM sites for {len(gene_counts)} genes")

# Convert to dataframe for easier analysis
counts_df = pd.DataFrame.from_dict(gene_counts, orient='index')
counts_df = counts_df.fillna(0)  # Fill missing values with 0

print(f"\nCounts dataframe shape: {counts_df.shape}")
print("\nFirst few rows of counts dataframe:")
print(counts_df.head())

# Save intermediate result
counts_path = os.path.join(tmp_dir, "asm_counts_per_sample.csv")
counts_df.to_csv(counts_path)
print(f"\nSaved ASM counts per sample to: {counts_path}")
</execute>
<observation>NameError("name 'asm_sites' is not defined")</observation>
I need to reload the data again.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# Define paths
asm_sites_path = "benchmark/dataset/ASMdb/mock/mock_asm_sites.csv"
genes_path = "benchmark/dataset/ASMdb/mock/mock_genes.csv"

# Load data
asm_sites = pd.read_csv(asm_sites_path)
genes = pd.read_csv(genes_path)

# Create gene regions with 3kb upstream
print("Creating gene regions with 3kb upstream...")

# Make a copy of genes dataframe
gene_regions = genes.copy()

# For + strand: upstream region is [start - 3000, start)
# For - strand: upstream region is [end, end + 3000)
# We'll create extended regions that include both gene body and upstream
gene_regions['region_start'] = gene_regions.apply(
    lambda row: row['start'] - 3000 if row['strand'] == '+' else row['start'], 
    axis=1
)
gene_regions['region_end'] = gene_regions.apply(
    lambda row: row['end'] if row['strand'] == '+' else row['end'] + 3000, 
    axis=1
)

# Ensure region_start is not negative (minimum 0)
gene_regions['region_start'] = gene_regions['region_start'].clip(lower=0)

print(f"Created gene regions for {len(gene_regions)} genes")

# Function to count ASM sites in gene regions for each sample
print("\nCounting ASM sites in gene regions for each sample...")

# Get unique samples
unique_samples = asm_sites['sample_id'].unique()
print(f"Number of samples: {len(unique_samples)}")

# Initialize a dictionary to store counts
gene_counts = {}

# Process each sample
for sample in unique_samples:
    print(f"Processing sample: {sample}")
    
    # Get ASM sites for this sample
    sample_sites = asm_sites[asm_sites['sample_id'] == sample]
    
    # For each gene, count ASM sites within its region
    for _, gene_row in gene_regions.iterrows():
        gene_id = gene_row['gene_id']
        chrom = gene_row['chrom']
        region_start = gene_row['region_start']
        region_end = gene_row['region_end']
        
        # Filter ASM sites for this chromosome
        chrom_sites = sample_sites[sample_sites['chrom'] == chrom]
        
        # Count sites within region
        count = ((chrom_sites['pos'] >= region_start) & (chrom_sites['pos'] <= region_end)).sum()
        
        # Initialize gene in dictionary if not present
        if gene_id not in gene_counts:
            gene_counts[gene_id] = {}
        
        # Store count for this sample
        gene_counts[gene_id][sample] = count

print(f"Processed {len(unique_samples)} samples")
print(f"Counted ASM sites for {len(gene_counts)} genes")

# Convert to dataframe for easier analysis
counts_df = pd.DataFrame.from_dict(gene_counts, orient='index')
counts_df = counts_df.fillna(0)  # Fill missing values with 0

print(f"\nCounts dataframe shape: {counts_df.shape}")
print("\nFirst few rows of counts dataframe:")
print(counts_df.head())

# Save intermediate result
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"
os.makedirs(tmp_dir, exist_ok=True)
counts_path = os.path.join(tmp_dir, "asm_counts_per_sample.csv")
counts_df.to_csv(counts_path)
print(f"\nSaved ASM counts per sample to: {counts_path}")
</execute>
<observation>Creating gene regions with 3kb upstream...
Created gene regions for 1000 genes

Counting ASM sites in gene regions for each sample...
Number of samples: 20
Processing sample: Sample_12
Processing sample: Sample_07
Processing sample: Sample_15
Processing sample: Sample_10
Processing sample: Sample_19
Processing sample: Sample_14
Processing sample: Sample_03
Processing sample: Sample_08
Processing sample: Sample_17
Processing sample: Sample_13
Processing sample: Sample_18
Processing sample: Sample_05
Processing sample: Sample_04
Processing sample: Sample_11
Processing sample: Sample_20
Processing sample: Sample_16
Processing sample: Sample_02
Processing sample: Sample_06
Processing sample: Sample_01
Processing sample: Sample_09
Processed 20 samples
Counted ASM sites for 1000 genes

Counts dataframe shape: (1000, 20)

First few rows of counts dataframe:
           Sample_12  Sample_07  Sample_15  ...  Sample_06  Sample_01  Sample_09
GENE_0001          1          0          0  ...          1          1          2
GENE_0002          0          0          0  ...          0          0          0
GENE_0003          0          0          0  ...          0          0          0
GENE_0004          0          0          0  ...          0          0          0
GENE_0005          0          0          0  ...          0          0          0

[5 rows x 20 columns]

Saved ASM counts per sample to: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/asm_counts_per_sample.csv
</observation>
Good! Now I need to aggregate counts across all samples to get frequency per gene. According to the task description, I need to count "the frequency of genes covered by ASM" - which means for each gene, I need to count in how many samples it has at least one ASM site (not the total number of ASM sites). Let me update my plan:

1. [✓] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [✓] Load the data into appropriate data structures
3. [✓] Define gene regions: gene body + 3kb upstream
4. [✓] For each sample, count ASM sites within each gene region
5. [ ] Aggregate counts across all samples to get frequency per gene
6. [ ] Sort genes by frequency and select top 100
7. [ ] Save results to the specified output file
8. [ ] Ensure all intermediate files are stored in the specified temporary directory

Now I need to compute frequency: for each gene, count how many samples have at least one ASM site in its region.

<execute>
# Compute frequency: number of samples with at least one ASM site per gene
print("Computing frequency of genes covered by ASM across samples...")

# Convert counts to binary (1 if count > 0, 0 otherwise)
binary_counts = (counts_df > 0).astype(int)

# Sum across samples to get frequency
gene_frequencies = binary_counts.sum(axis=1)

print(f"Computed frequencies for {len(gene_frequencies)} genes")
print("\nFirst few genes with their frequencies:")
print(gene_frequencies.head(10))

# Create a dataframe with gene_id and frequency
frequency_df = pd.DataFrame({
    'gene_id': gene_frequencies.index,
    'frequency': gene_frequencies.values
})

print(f"\nFrequency dataframe shape: {frequency_df.shape}")
print("\nFirst few rows of frequency dataframe:")
print(frequency_df.head())

# Save intermediate result
freq_path = os.path.join(tmp_dir, "gene_frequencies.csv")
frequency_df.to_csv(freq_path, index=False)
print(f"\nSaved gene frequencies to: {freq_path}")
</execute>
<observation>NameError("name 'counts_df' is not defined")</observation>
I need to reload the data and recalculate.

<execute>
import pandas as pd
import os
import numpy as np
from pathlib import Path

# Define paths
asm_sites_path = "benchmark/dataset/ASMdb/mock/mock_asm_sites.csv"
genes_path = "benchmark/dataset/ASMdb/mock/mock_genes.csv"

# Load data
asm_sites = pd.read_csv(asm_sites_path)
genes = pd.read_csv(genes_path)

# Create temporary directory
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"
os.makedirs(tmp_dir, exist_ok=True)

# Load the counts dataframe we saved earlier
counts_path = os.path.join(tmp_dir, "asm_counts_per_sample.csv")
if os.path.exists(counts_path):
    print(f"Loading counts from: {counts_path}")
    counts_df = pd.read_csv(counts_path, index_col=0)
    print(f"Loaded counts dataframe shape: {counts_df.shape}")
else:
    print("Counts file not found, need to recalculate...")
    # We would need to recalculate here, but let's assume it exists
    
# Compute frequency: number of samples with at least one ASM site per gene
print("\nComputing frequency of genes covered by ASM across samples...")

# Convert counts to binary (1 if count > 0, 0 otherwise)
binary_counts = (counts_df > 0).astype(int)

# Sum across samples to get frequency
gene_frequencies = binary_counts.sum(axis=1)

print(f"Computed frequencies for {len(gene_frequencies)} genes")
print("\nFirst few genes with their frequencies:")
print(gene_frequencies.head(10))

# Create a dataframe with gene_id and frequency
frequency_df = pd.DataFrame({
    'gene_id': gene_frequencies.index,
    'frequency': gene_frequencies.values
})

print(f"\nFrequency dataframe shape: {frequency_df.shape}")
print("\nFirst few rows of frequency dataframe:")
print(frequency_df.head())

# Save intermediate result
freq_path = os.path.join(tmp_dir, "gene_frequencies.csv")
frequency_df.to_csv(freq_path, index=False)
print(f"\nSaved gene frequencies to: {freq_path}")
</execute>
<observation>Loading counts from: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/asm_counts_per_sample.csv
Loaded counts dataframe shape: (1000, 20)

Computing frequency of genes covered by ASM across samples...
Computed frequencies for 1000 genes

First few genes with their frequencies:
GENE_0001    15
GENE_0002     0
GENE_0003     0
GENE_0004     0
GENE_0005     0
GENE_0006     0
GENE_0007     2
GENE_0008     0
GENE_0009     0
GENE_0010     1
dtype: int64

Frequency dataframe shape: (1000, 2)

First few rows of frequency dataframe:
     gene_id  frequency
0  GENE_0001         15
1  GENE_0002          0
2  GENE_0003          0
3  GENE_0004          0
4  GENE_0005          0

Saved gene frequencies to: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/gene_frequencies.csv
</observation>
Great! Now I need to sort genes by frequency and select the top 100. Let me update my plan:

1. [✓] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [✓] Load the data into appropriate data structures
3. [✓] Define gene regions: gene body + 3kb upstream
4. [✓] For each sample, count ASM sites within each gene region
5. [✓] Aggregate counts across all samples to get frequency per gene
6. [ ] Sort genes by frequency and select top 100
7. [ ] Save results to the specified output file
8. [ ] Ensure all intermediate files are stored in the specified temporary directory

Now let me sort and select the top 100 genes.

<execute>
# Sort genes by frequency in descending order and select top 100
print("Sorting genes by frequency and selecting top 100...")

sorted_freq_df = frequency_df.sort_values(by='frequency', ascending=False)
top_100_genes = sorted_freq_df.head(100)

print(f"Top 100 genes selected")
print(f"\nFrequency distribution in top 100:")
print(top_100_genes['frequency'].describe())

print("\nTop 10 genes with highest frequency:")
print(top_100_genes.head(10))

print("\nBottom 10 genes in top 100:")
print(top_100_genes.tail(10))

# Check if we have enough genes with non-zero frequency
non_zero_count = (frequency_df['frequency'] > 0).sum()
print(f"\nNumber of genes with non-zero frequency: {non_zero_count}")
print(f"Number of genes with zero frequency: {len(frequency_df) - non_zero_count}")

# Save intermediate result
top_100_path = os.path.join(tmp_dir, "top_100_genes.csv")
top_100_genes.to_csv(top_100_path, index=False)
print(f"\nSaved top 100 genes to: {top_100_path}")
</execute>
<observation>NameError("name 'frequency_df' is not defined")</observation>
I need to reload the frequency data.

<execute>
import pandas as pd
import os

# Define temporary directory
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"

# Load frequency data
freq_path = os.path.join(tmp_dir, "gene_frequencies.csv")
frequency_df = pd.read_csv(freq_path)

print(f"Loaded frequency dataframe shape: {frequency_df.shape}")

# Sort genes by frequency in descending order and select top 100
print("Sorting genes by frequency and selecting top 100...")

sorted_freq_df = frequency_df.sort_values(by='frequency', ascending=False)
top_100_genes = sorted_freq_df.head(100)

print(f"Top 100 genes selected")
print(f"\nFrequency distribution in top 100:")
print(top_100_genes['frequency'].describe())

print("\nTop 10 genes with highest frequency:")
print(top_100_genes.head(10))

print("\nBottom 10 genes in top 100:")
print(top_100_genes.tail(10))

# Check if we have enough genes with non-zero frequency
non_zero_count = (frequency_df['frequency'] > 0).sum()
print(f"\nNumber of genes with non-zero frequency: {non_zero_count}")
print(f"Number of genes with zero frequency: {len(frequency_df) - non_zero_count}")

# Save intermediate result
top_100_path = os.path.join(tmp_dir, "top_100_genes.csv")
top_100_genes.to_csv(top_100_path, index=False)
print(f"\nSaved top 100 genes to: {top_100_path}")
</execute>
<observation>Loaded frequency dataframe shape: (1000, 2)
Sorting genes by frequency and selecting top 100...
Top 100 genes selected

Frequency distribution in top 100:
count    100.000000
mean      17.690000
std        1.195066
min       16.000000
25%       17.000000
50%       18.000000
75%       19.000000
max       20.000000
Name: frequency, dtype: float64

Top 10 genes with highest frequency:
       gene_id  frequency
562  GENE_0563         20
682  GENE_0683         20
580  GENE_0581         20
251  GENE_0252         20
898  GENE_0899         20
412  GENE_0413         20
919  GENE_0920         20
84   GENE_0085         20
396  GENE_0397         19
991  GENE_0992         19

Bottom 10 genes in top 100:
       gene_id  frequency
303  GENE_0304         16
306  GENE_0307         16
33   GENE_0034         16
225  GENE_0226         16
199  GENE_0200         16
803  GENE_0804         16
824  GENE_0825         16
455  GENE_0456         16
452  GENE_0453         16
923  GENE_0924         16

Number of genes with non-zero frequency: 353
Number of genes with zero frequency: 647

Saved top 100 genes to: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/top_100_genes.csv
</observation>
Perfect! Now I need to save the final result to the specified output file. Let me update my plan:

1. [✓] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [✓] Load the data into appropriate data structures
3. [✓] Define gene regions: gene body + 3kb upstream
4. [✓] For each sample, count ASM sites within each gene region
5. [✓] Aggregate counts across all samples to get frequency per gene
6. [✓] Sort genes by frequency and select top 100
7. [ ] Save results to the specified output file
8. [ ] Ensure all intermediate files are stored in the specified temporary directory

Now I need to save the top 100 genes to the final output path.

<execute>
# Save final result to the specified output file
output_path = "/root/autodl-tmp/biomni_v20260208_pred_results/deepseek-v3.2-fast/asmdb_annotate.csv"

# Create output directory if it doesn't exist
output_dir = os.path.dirname(output_path)
os.makedirs(output_dir, exist_ok=True)

# Save the top 100 genes to the output file
top_100_genes.to_csv(output_path, index=False)
print(f"Saved top 100 genes to: {output_path}")
print(f"\nOutput file contents (first 10 rows):")
print(pd.read_csv(output_path).head(10))

# Also verify the file was created
print(f"\nFile exists: {os.path.exists(output_path)}")
print(f"File size: {os.path.getsize(output_path)} bytes")
</execute>
<observation>NameError("name 'os' is not defined")</observation>
I need to import os.

<execute>
import os
import pandas as pd

# Define output path
output_path = "/root/autodl-tmp/biomni_v20260208_pred_results/deepseek-v3.2-fast/asmdb_annotate.csv"

# Load the top 100 genes from temporary file
tmp_dir = "/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate"
top_100_path = os.path.join(tmp_dir, "top_100_genes.csv")
top_100_genes = pd.read_csv(top_100_path)

print(f"Loaded top 100 genes from: {top_100_path}")

# Create output directory if it doesn't exist
output_dir = os.path.dirname(output_path)
os.makedirs(output_dir, exist_ok=True)

# Save the top 100 genes to the output file
top_100_genes.to_csv(output_path, index=False)
print(f"Saved top 100 genes to: {output_path}")
print(f"\nOutput file contents (first 10 rows):")
print(pd.read_csv(output_path).head(10))

# Also verify the file was created
print(f"\nFile exists: {os.path.exists(output_path)}")
print(f"File size: {os.path.getsize(output_path)} bytes")
</execute>
<observation>Loaded top 100 genes from: /root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/top_100_genes.csv
Saved top 100 genes to: /root/autodl-tmp/biomni_v20260208_pred_results/deepseek-v3.2-fast/asmdb_annotate.csv

Output file contents (first 10 rows):
     gene_id  frequency
0  GENE_0563         20
1  GENE_0683         20
2  GENE_0581         20
3  GENE_0252         20
4  GENE_0899         20
5  GENE_0413         20
6  GENE_0920         20
7  GENE_0085         20
8  GENE_0397         19
9  GENE_0992         19

File exists: True
File size: 1318 bytes
</observation>
Excellent! Now let me update my plan to mark all steps as completed:

1. [✓] Understand the data structure: examine the provided CSV files (ASM sites and genes)
2. [✓] Load the data into appropriate data structures
3. [✓] Define gene regions: gene body + 3kb upstream
4. [✓] For each sample, count ASM sites within each gene region
5. [✓] Aggregate counts across all samples to get frequency per gene
6. [✓] Sort genes by frequency and select top 100
7. [✓] Save results to the specified output file
8. [✓] Ensure all intermediate files are stored in the specified temporary directory

All steps are completed. Let me provide a final summary and the solution.

<solution>
The task has been successfully completed. The top 100 genes that most frequently exhibit Allele-Specific Methylation (ASM) across the population of samples have been identified and saved to the specified output file.

**Summary of the process:**

1. **Data Loading**: Loaded ASM sites from `benchmark/dataset/ASMdb/mock/mock_asm_sites.csv` (5,000 sites across 20 samples) and gene annotations from `benchmark/dataset/ASMdb/mock/mock_genes.csv` (1,000 genes).

2. **Gene Region Definition**: For each gene, defined a region encompassing the gene body plus 3kb upstream. For genes on the '+' strand, upstream is before the start; for '-' strand, upstream is after the end.

3. **ASM Site Counting**: For each sample, counted the number of ASM sites within each gene's defined region.

4. **Frequency Calculation**: For each gene, computed the frequency as the number of samples (out of 20) that have at least one ASM site within the gene's region.

5. **Top 100 Selection**: Sorted genes by frequency in descending order and selected the top 100 genes.

6. **Output Generation**: Saved the top 100 genes with their frequencies to `/root/autodl-tmp/biomni_v20260208_pred_results/deepseek-v3.2-fast/asmdb_annotate.csv`.

**Key Findings:**
- Total genes analyzed: 1,000
- Genes with at least one ASM site in any sample: 353
- Genes with zero ASM sites across all samples: 647
- Frequency range in top 100 genes: 16 to 20 (out of 20 samples)
- Top genes have ASM sites in 16-20 samples, indicating high frequency of ASM occurrence

**Output File Format:**
The output CSV file contains two columns: `gene_id` and `frequency`, with 100 rows representing the top 100 genes sorted by frequency in descending order.

All intermediate files have been stored in `/root/autodl-tmp/biomni_v20260208_tmp/deepseek-v3.2-fast/asmdb_annotate/` for reference and reproducibility.
</solution>