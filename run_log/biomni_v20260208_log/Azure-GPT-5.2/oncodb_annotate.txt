Perform a Cox Proportional Hazards regression analysis on the provided `benchmark/dataset/OncoDB/rossi_dataset.csv`. 

The model should use `week` as the duration column and `arrest` as the event column. 

All other columns should be used as covariates. 

Save the resulting regression summary table to a CSV file named `/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv`.

Output example:
```
covariate,coef,exp(coef),se(coef),coef lower 95%,coef upper 95%,exp(coef) lower 95%,exp(coef) upper 95%,cmp to,z,p,-log2(p)
age,0.02,1.02,0.01,0.00,0.04,1.00,1.04,age,2.00,0.045,-4.47
``` 

All intermidate results should be saved to `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate` directory.

<execute>#!BASH
set -euo pipefail

echo "=== Research log: Cox PH regression on rossi_dataset.csv ==="

DATASET="benchmark/dataset/OncoDB/rossi_dataset.csv"
OUTDIR_TMP="/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate"
OUTCSV="/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv"

mkdir -p "$OUTDIR_TMP"
mkdir -p "$(dirname "$OUTCSV")"

echo "[1] Checking input file exists: $DATASET"
test -f "$DATASET"
echo "    OK"

echo "[2] Running Cox PH in Python (lifelines if available; else statsmodels)"
python - <<'PY'
import os, sys, math
import pandas as pd
from pathlib import Path

DATASET="benchmark/dataset/OncoDB/rossi_dataset.csv"
OUTDIR_TMP=Path("/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate")
OUTCSV=Path("/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv")

OUTDIR_TMP.mkdir(parents=True, exist_ok=True)
OUTCSV.parent.mkdir(parents=True, exist_ok=True)

print("Step 1/5: Load dataset")
df = pd.read_csv(DATASET)
print("  shape:", df.shape)
print("  columns:", list(df.columns))
df.to_csv(OUTDIR_TMP/"input_loaded.csv", index=False)

duration_col="week"
event_col="arrest"
assert duration_col in df.columns, f"Missing duration col {duration_col}"
assert event_col in df.columns, f"Missing event col {event_col}"

covariates=[c for c in df.columns if c not in [duration_col, event_col]]
print("  covariates:", covariates)

print("Step 2/5: Basic cleaning (drop missing in required columns)")
req=[duration_col, event_col]+covariates
df2=df[req].copy()
before=df2.shape[0]
df2=df2.dropna()
after=df2.shape[0]
print(f"  dropped rows with NA: {before-after}")
df2.to_csv(OUTDIR_TMP/"input_clean.csv", index=False)

# ensure numeric (coerce); keep non-numeric as category via one-hot
print("Step 3/5: One-hot encode non-numeric covariates if any")
X=df2[covariates]
non_numeric=[c for c in X.columns if not pd.api.types.is_numeric_dtype(X[c])]
print("  non-numeric covariates:", non_numeric)

if non_numeric:
    X_enc=pd.get_dummies(X, columns=non_numeric, drop_first=True)
else:
    X_enc=X.copy()

design = pd.concat([df2[[duration_col,event_col]], X_enc], axis=1)
design.to_csv(OUTDIR_TMP/"design_matrix.csv", index=False)
print("  design matrix shape:", design.shape)

print("Step 4/5: Fit Cox proportional hazards model")
used_backend=None
try:
    from lifelines import CoxPHFitter
    cph=CoxPHFitter()
    cph.fit(design, duration_col=duration_col, event_col=event_col, show_progress=False)
    used_backend="lifelines"
    summ=cph.summary.copy()
    summ.to_csv(OUTDIR_TMP/"lifelines_summary_raw.csv", index=True)
    print("  fitted with lifelines; summary rows:", summ.shape[0])

    # lifelines columns: coef, exp(coef), se(coef), coef lower 95%, coef upper 95%, exp(coef) lower 95%, exp(coef) upper 95%, cmp to, z, p, -log2(p)
    out = summ.reset_index().rename(columns={"index":"covariate"})
    # ensure -log2(p) present
    if "-log2(p)" not in out.columns and "p" in out.columns:
        out["-log2(p)"]=out["p"].apply(lambda p: -math.log(p,2) if p>0 else float("inf"))
    # keep and order columns as requested
    cols=["covariate","coef","exp(coef)","se(coef)","coef lower 95%","coef upper 95%",
          "exp(coef) lower 95%","exp(coef) upper 95%","cmp to","z","p","-log2(p)"]
    # Some versions use slightly different naming for se
    if "se(coef)" not in out.columns and "se" in out.columns:
        out=out.rename(columns={"se":"se(coef)"})
    # cmp to sometimes called 'cmp to' already; else create
    if "cmp to" not in out.columns:
        out["cmp to"]=out["covariate"]
    # z might be missing if robust; fallback compute
    if "z" not in out.columns and "p" in out.columns:
        out["z"]=float("nan")
    out = out[cols]
except Exception as e:
    print("  lifelines not available or failed:", repr(e))
    print("  trying statsmodels PHReg")
    import statsmodels.api as sm
    from statsmodels.duration.hazard_regression import PHReg

    y_time = design[duration_col].astype(float).values
    y_event = design[event_col].astype(int).values
    X = design.drop(columns=[duration_col,event_col])
    X = sm.add_constant(X, has_constant='add')
    model=PHReg(endog=y_time, exog=X, status=y_event)
    res=model.fit()
    used_backend="statsmodels"
    # Build table
    params=res.params
    bse=res.bse
    z=params/bse
    p=res.pvalues
    ci=res.conf_int()
    coef=params
    expcoef=pd.Series(np.exp(coef), index=coef.index)
    out=pd.DataFrame({
        "covariate": coef.index,
        "coef": coef.values,
        "exp(coef)": expcoef.values,
        "se(coef)": bse.values,
        "coef lower 95%": ci[0].values,
        "coef upper 95%": ci[1].values,
        "exp(coef) lower 95%": np.exp(ci[0].values),
        "exp(coef) upper 95%": np.exp(ci[1].values),
        "cmp to": coef.index,
        "z": z.values,
        "p": p.values,
        "-log2(p)": [-math.log(v,2) if v>0 else float("inf") for v in p.values],
    })
    out.to_csv(OUTDIR_TMP/"statsmodels_summary_raw.csv", index=False)

print("  backend used:", used_backend)

print("Step 5/5: Save final summary CSV")
out.to_csv(OUTCSV, index=False)
out.to_csv(OUTDIR_TMP/"final_summary.csv", index=False)

print("  wrote:", str(OUTCSV))
print("  preview:")
print(out.head(10).to_string(index=False))
PY

echo "[3] Listing intermediate outputs"
ls -la "$OUTDIR_TMP" | sed -n '1,200p'

echo "=== Done ==="
</execute>
<observation>Error running Bash script (exit code 1):
Traceback (most recent call last):
  File "<stdin>", line 53, in <module>
ModuleNotFoundError: No module named 'lifelines'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 82, in <module>
ModuleNotFoundError: No module named 'statsmodels'
</observation>
<execute>#!BASH
set -euo pipefail

echo "=== Research log: Cox PH regression (R survival) on rossi_dataset.csv ==="

DATASET="benchmark/dataset/OncoDB/rossi_dataset.csv"
OUTDIR_TMP="/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate"
OUTCSV="/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv"

mkdir -p "$OUTDIR_TMP"
mkdir -p "$(dirname "$OUTCSV")"

echo "[1] Checking input file exists: $DATASET"
test -f "$DATASET"
echo "    OK"

echo "[2] Running Cox PH in R (survival::coxph) and exporting summary table"
Rscript - <<RSCRIPT
options(stringsAsFactors = FALSE)

dataset <- "$DATASET"
outdir  <- "$OUTDIR_TMP"
outcsv  <- "$OUTCSV"

dir.create(outdir, recursive=TRUE, showWarnings=FALSE)
dir.create(dirname(outcsv), recursive=TRUE, showWarnings=FALSE)

cat("Step 1/5: Load dataset\\n")
df <- read.csv(dataset, check.names=FALSE)
cat("  shape:", nrow(df), "x", ncol(df), "\\n")
cat("  columns:", paste(colnames(df), collapse=", "), "\\n")
write.csv(df, file=file.path(outdir, "input_loaded.csv"), row.names=FALSE)

duration_col <- "week"
event_col <- "arrest"
stopifnot(duration_col %in% names(df))
stopifnot(event_col %in% names(df))

covariates <- setdiff(names(df), c(duration_col, event_col))
cat("  covariates:", paste(covariates, collapse=", "), "\\n")

cat("Step 2/5: Drop rows with NA in required columns\\n")
req <- c(duration_col, event_col, covariates)
df2 <- df[, req, drop=FALSE]
before <- nrow(df2)
df2 <- df2[complete.cases(df2), , drop=FALSE]
after <- nrow(df2)
cat("  dropped rows with NA:", before - after, "\\n")
write.csv(df2, file=file.path(outdir, "input_clean.csv"), row.names=FALSE)

cat("Step 3/5: Fit Cox PH model with all covariates\\n")
suppressPackageStartupMessages(library(survival))

# Build formula: Surv(week, arrest) ~ .
fml <- as.formula(paste0("Surv(", duration_col, ", ", event_col, ") ~ ."))
fit <- coxph(fml, data=df2, ties="efron", model=TRUE, x=TRUE)
saveRDS(fit, file=file.path(outdir, "coxph_model.rds"))

cat("Step 4/5: Build summary table (match requested columns)\\n")
s <- summary(fit)

# coefficients matrix: coef exp(coef) se(coef) z Pr(>|z|)
coef_mat <- as.data.frame(s$coefficients)
coef_mat$covariate <- rownames(coef_mat)
rownames(coef_mat) <- NULL

# conf.int matrix: exp(coef) exp(-coef) lower .95 upper .95
ci_mat <- as.data.frame(s$conf.int)
ci_mat$covariate <- rownames(ci_mat)
rownames(ci_mat) <- NULL

# Merge
m <- merge(coef_mat, ci_mat, by="covariate", all=TRUE)

# Standardize column names from survival output
# survival names are typically: coef, exp(coef), se(coef), z, Pr(>|z|)
pcol <- grep("^Pr\\(", names(m), value=TRUE)
if (length(pcol) != 1) stop("Could not find p-value column in coxph summary.")
names(m)[names(m)==pcol] <- "p"

# ci lower/upper are typically "lower .95" and "upper .95" in s$conf.int
# Add coef CI as log of exp(CI)
if (!("lower .95" %in% names(m)) || !("upper .95" %in% names(m))) {
  stop("Could not find lower .95 / upper .95 in conf.int table.")
}

m[["coef lower 95%"]] <- log(m[["lower .95"]])
m[["coef upper 95%"]] <- log(m[["upper .95"]])

# Prepare final columns per spec
out <- data.frame(
  covariate = m$covariate,
  coef = m$coef,
  `exp(coef)` = m[["exp(coef).x"]],
  `se(coef)` = m[["se(coef)"]],
  `coef lower 95%` = m[["coef lower 95%"]],
  `coef upper 95%` = m[["coef upper 95%"]],
  `exp(coef) lower 95%` = m[["lower .95"]],
  `exp(coef) upper 95%` = m[["upper .95"]],
  `cmp to` = m$covariate,
  z = m$z,
  p = m$p,
  `-log2(p)` = -log(m$p, base=2),
  check.names = FALSE
)

# survival's merge duplicated exp(coef) column name to exp(coef).x/exp(coef).y
# exp(coef).y is from conf.int and should match; prefer .x from coefficients
if (all(is.na(out[["exp(coef)"]])) && "exp(coef).y" %in% names(m)) {
  out[["exp(coef)"]] <- m[["exp(coef).y"]]
}

write.csv(out, file=file.path(outdir, "final_summary.csv"), row.names=FALSE)

cat("Step 5/5: Save final output CSV\\n")
write.csv(out, file=outcsv, row.names=FALSE)

cat("Wrote:", outcsv, "\\n")
cat("Preview (first 10 rows):\\n")
print(utils::head(out, 10))
RSCRIPT

echo "[3] Listing intermediate outputs"
ls -la "$OUTDIR_TMP" | sed -n '1,200p'

echo "=== Done ==="

echo
echo "PLAN / PROGRESS:"
cat <<'PLAN'
1. [✓] Validate input paths and create required output directories
2. [✓] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [✓] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [✓] Generate regression summary table with requested columns and save intermediate summary CSV
5. [✓] Save final summary table to /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv
PLAN
</execute>
<observation>Error running Bash script (exit code 1):
/tmp/tmp3t5gef_r.sh: line 18: coefficients: unbound variable
</observation>
<execute>#!BASH
set -euo pipefail

echo "=== Research log: Cox PH regression (R survival) on rossi_dataset.csv ==="

DATASET="benchmark/dataset/OncoDB/rossi_dataset.csv"
OUTDIR_TMP="/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate"
OUTCSV="/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv"

mkdir -p "$OUTDIR_TMP"
mkdir -p "$(dirname "$OUTCSV")"

echo
echo "PLAN:"
cat <<'PLAN'
1. [ ] Validate input paths and create required output directories
2. [ ] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [ ] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [ ] Generate regression summary table with requested columns and save intermediate summary CSV
5. [ ] Save final summary table to final output CSV path
PLAN
echo

echo "[Step 1] Validate input and create directories"
test -f "$DATASET"
echo "  Input exists."
echo "  Tmp dir: $OUTDIR_TMP"
echo "  Out csv: $OUTCSV"
echo
echo "Updated plan:"
cat <<'PLAN'
1. [✓] Validate input paths and create required output directories
2. [ ] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [ ] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [ ] Generate regression summary table with requested columns and save intermediate summary CSV
5. [ ] Save final summary table to final output CSV path
PLAN
echo

echo "[Step 2-5] Run R pipeline"
# IMPORTANT: use single-quoted heredoc to prevent bash from expanding things like $coefficients
Rscript - <<'RSCRIPT'
options(stringsAsFactors = FALSE)

dataset <- "benchmark/dataset/OncoDB/rossi_dataset.csv"
outdir  <- "/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate"
outcsv  <- "/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv"

dir.create(outdir, recursive=TRUE, showWarnings=FALSE)
dir.create(dirname(outcsv), recursive=TRUE, showWarnings=FALSE)

cat("Step 2/5: Load dataset\n")
df <- read.csv(dataset, check.names=FALSE)
cat("  shape:", nrow(df), "x", ncol(df), "\n")
cat("  columns:", paste(colnames(df), collapse=", "), "\n")
write.csv(df, file=file.path(outdir, "input_loaded.csv"), row.names=FALSE)

duration_col <- "week"
event_col <- "arrest"
stopifnot(duration_col %in% names(df))
stopifnot(event_col %in% names(df))

covariates <- setdiff(names(df), c(duration_col, event_col))
cat("  covariates:", paste(covariates, collapse=", "), "\n")

cat("Step 3/5: Drop rows with NA in required columns\n")
req <- c(duration_col, event_col, covariates)
df2 <- df[, req, drop=FALSE]
before <- nrow(df2)
df2 <- df2[complete.cases(df2), , drop=FALSE]
after <- nrow(df2)
cat("  dropped rows with NA:", before - after, "\n")
write.csv(df2, file=file.path(outdir, "input_clean.csv"), row.names=FALSE)

cat("Step 4/5: Fit Cox PH model and build summary table\n")
suppressPackageStartupMessages(library(survival))

fml <- as.formula(paste0("Surv(", duration_col, ", ", event_col, ") ~ ."))
fit <- coxph(fml, data=df2, ties="efron", model=TRUE, x=TRUE)
saveRDS(fit, file=file.path(outdir, "coxph_model.rds"))

s <- summary(fit)

coef_mat <- as.data.frame(s$coefficients)
coef_mat$covariate <- rownames(coef_mat)
rownames(coef_mat) <- NULL

ci_mat <- as.data.frame(s$conf.int)
ci_mat$covariate <- rownames(ci_mat)
rownames(ci_mat) <- NULL

m <- merge(coef_mat, ci_mat, by="covariate", all=TRUE)

# Identify p-value column (usually "Pr(>|z|)")
pcol <- grep("^Pr\\(", names(m), value=TRUE)
if (length(pcol) != 1) stop("Could not uniquely identify p-value column in coxph summary.")
names(m)[names(m)==pcol] <- "p"

# In merge, exp(coef) from coefficients becomes exp(coef).x; from conf.int becomes exp(coef).y
exp_coef_col <- if ("exp(coef).x" %in% names(m)) "exp(coef).x" else if ("exp(coef)" %in% names(m)) "exp(coef)" else "exp(coef).y"

if (!("lower .95" %in% names(m)) || !("upper .95" %in% names(m))) {
  stop("Could not find lower .95 / upper .95 in conf.int table.")
}

out <- data.frame(
  covariate = m$covariate,
  coef = m$coef,
  `exp(coef)` = m[[exp_coef_col]],
  `se(coef)` = m[["se(coef)"]],
  `coef lower 95%` = log(m[["lower .95"]]),
  `coef upper 95%` = log(m[["upper .95"]]),
  `exp(coef) lower 95%` = m[["lower .95"]],
  `exp(coef) upper 95%` = m[["upper .95"]],
  `cmp to` = m$covariate,
  z = m$z,
  p = m$p,
  `-log2(p)` = -log(m$p, base=2),
  check.names = FALSE
)

write.csv(out, file=file.path(outdir, "final_summary.csv"), row.names=FALSE)

cat("Step 5/5: Save final output CSV\n")
write.csv(out, file=outcsv, row.names=FALSE)

cat("Wrote:", outcsv, "\n")
cat("Preview (first 10 rows):\n")
print(utils::head(out, 10))
RSCRIPT

echo
echo "[Post] Listing intermediate outputs"
ls -la "$OUTDIR_TMP" | sed -n '1,200p'

echo
echo "Updated plan:"
cat <<'PLAN'
1. [✓] Validate input paths and create required output directories
2. [✓] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [✓] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [✓] Generate regression summary table with requested columns and save intermediate summary CSV
5. [✓] Save final summary table to /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv
PLAN

echo "=== Done ==="
</execute>
<observation>=== Research log: Cox PH regression (R survival) on rossi_dataset.csv ===

PLAN:
1. [ ] Validate input paths and create required output directories
2. [ ] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [ ] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [ ] Generate regression summary table with requested columns and save intermediate summary CSV
5. [ ] Save final summary table to final output CSV path

[Step 1] Validate input and create directories
  Input exists.
  Tmp dir: /root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate
  Out csv: /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv

Updated plan:
1. [✓] Validate input paths and create required output directories
2. [ ] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [ ] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [ ] Generate regression summary table with requested columns and save intermediate summary CSV
5. [ ] Save final summary table to final output CSV path

[Step 2-5] Run R pipeline
Step 2/5: Load dataset
  shape: 432 x 9 
  columns: week, arrest, fin, age, race, wexp, mar, paro, prio 
  covariates: fin, age, race, wexp, mar, paro, prio 
Step 3/5: Drop rows with NA in required columns
  dropped rows with NA: 0 
Step 4/5: Fit Cox PH model and build summary table
Step 5/5: Save final output CSV
Wrote: /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv 
Preview (first 10 rows):
  covariate        coef exp(coef)   se(coef) coef lower 95% coef upper 95%
1       age -0.05743774 0.9441807 0.02199947    -0.10055591   -0.014319573
2       fin -0.37942217 0.6842567 0.19137948    -0.75451906   -0.004325277
3       mar -0.43370388 0.6481041 0.38186806    -1.18215152    0.314743762
4      paro -0.08487108 0.9186307 0.19575667    -0.46854711    0.298804944
5      prio  0.09149708 1.0958136 0.02864855     0.03534695    0.147647207
6      race  0.31389979 1.3687526 0.30799278    -0.28975496    0.917554537
7      wexp -0.14979570 0.8608838 0.21222430    -0.56574767    0.266156280
  exp(coef) lower 95% exp(coef) upper 95% cmp to          z           p
1           0.9043345           0.9857825    age -2.6108693 0.009031240
2           0.4702367           0.9956841    fin -1.9825645 0.047416095
3           0.3066183           1.3699082    mar -1.1357427 0.256064243
4           0.6259110           1.3482466   paro -0.4335540 0.664612366
5           1.0359791           1.1591039   prio  3.1937770 0.001404245
6           0.7484469           2.5031615   race  1.0191791 0.308117967
7           0.5679354           1.3049390   wexp -0.7058367 0.480289694
  -log2(p)
1 6.790860
2 4.398479
3 1.965422
4 0.589415
5 9.475989
6 1.698445
7 1.058023

[Post] Listing intermediate outputs
total 68
drwxr-xr-x  2 root root   126 Feb  8 21:38 .
drwxr-xr-x 69 root root  4096 Feb  8 21:38 ..
-rw-r--r--  1 root root 23338 Feb  8 21:38 coxph_model.rds
-rw-r--r--  1 root root  8693 Feb  8 21:38 design_matrix.csv
-rw-r--r--  1 root root  1500 Feb  8 21:38 final_summary.csv
-rw-r--r--  1 root root  8711 Feb  8 21:38 input_clean.csv
-rw-r--r--  1 root root  8711 Feb  8 21:38 input_loaded.csv

Updated plan:
1. [✓] Validate input paths and create required output directories
2. [✓] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [✓] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [✓] Generate regression summary table with requested columns and save intermediate summary CSV
5. [✓] Save final summary table to /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv
=== Done ===
</observation>
<solution>
Reasoning: The Cox Proportional Hazards regression was successfully fit using `week` as the duration column and `arrest` as the event column, with all other columns (`fin, age, race, wexp, mar, paro, prio`) as covariates. Since Python packages `lifelines` and `statsmodels` were unavailable in the environment, the analysis was performed with R’s `survival::coxph`. All intermediate artifacts were written to the required tmp directory, and the final regression summary table was saved to the specified output CSV.

Updated plan:
1. [✓] Validate input paths and create required output directories
2. [✓] Load rossi_dataset.csv and save intermediate copies (loaded/clean)
3. [✓] Fit Cox proportional hazards model using week (duration) and arrest (event) with all other columns as covariates
4. [✓] Generate regression summary table with requested columns and save intermediate summary CSV
5. [✓] Save final summary table to /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv

Files saved:
- Final summary CSV:
  - `/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/oncodb_annotate.csv`
- Intermediate outputs directory:
  - `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/oncodb_annotate/`
    - `input_loaded.csv`
    - `input_clean.csv`
    - `design_matrix.csv`
    - `coxph_model.rds`
    - `final_summary.csv`
</solution>