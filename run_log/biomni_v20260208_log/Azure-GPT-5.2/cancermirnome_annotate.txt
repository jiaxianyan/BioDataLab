From the provided circulating miRNome abundance data (`benchmark/dataset/CancerMIRNome/circulating_miRNome_abundance.csv`), filter for the top 500 most abundant miRNAs based on the "Abundance" column. 

Save the list of their `miRNA_ID`s to a text file named `/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/cancermirnome_annotate.txt`.

Output example for reference:
```
xxx
xxx
```

All intermediate results should be saved to `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate`

<execute>
import os
import pandas as pd

print("Research log: Top 500 abundant miRNAs from circulating_miRNome_abundance.csv")

# Paths
infile = "benchmark/dataset/CancerMIRNome/circulating_miRNome_abundance.csv"
tmp_dir = "/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate"
out_txt = "/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/cancermirnome_annotate.txt"

os.makedirs(tmp_dir, exist_ok=True)
os.makedirs(os.path.dirname(out_txt), exist_ok=True)

plan = [
    "[ ] Load input CSV and validate required columns",
    "[ ] Sort by Abundance (desc) and select top 500",
    "[ ] Save intermediate tables to tmp directory",
    "[ ] Write miRNA_ID list to requested output text file"
]
print("\nPlan:")
for i, s in enumerate(plan, 1):
    print(f"{i}. {s}")

# Step 1: Load and validate
df = pd.read_csv(infile)
required = {"miRNA_ID", "Abundance"}
missing = required - set(df.columns)
if missing:
    raise ValueError(f"Missing required columns: {missing}. Available columns: {list(df.columns)}")

plan[0] = "[✓] Load input CSV and validate required columns"
print("\nUpdated plan:")
for i, s in enumerate(plan, 1):
    print(f"{i}. {s}")

# Step 2: Sort and select top 500
df2 = df.copy()
df2["Abundance"] = pd.to_numeric(df2["Abundance"], errors="coerce")
df2 = df2.dropna(subset=["Abundance"])
top500 = df2.sort_values("Abundance", ascending=False).head(500)

plan[1] = "[✓] Sort by Abundance (desc) and select top 500"
print("\nUpdated plan:")
for i, s in enumerate(plan, 1):
    print(f"{i}. {s}")

# Step 3: Save intermediates
raw_head_path = os.path.join(tmp_dir, "input_head.csv")
top500_path = os.path.join(tmp_dir, "top500_by_abundance.csv")
top500_ids_path = os.path.join(tmp_dir, "top500_miRNA_IDs.txt")

df.head(50).to_csv(raw_head_path, index=False)
top500.to_csv(top500_path, index=False)

ids = top500["miRNA_ID"].astype(str).tolist()
with open(top500_ids_path, "w") as f:
    f.write("\n".join(ids) + ("\n" if ids else ""))

plan[2] = "[✓] Save intermediate tables to tmp directory"
print("\nUpdated plan:")
for i, s in enumerate(plan, 1):
    print(f"{i}. {s}")

# Step 4: Write final output
with open(out_txt, "w") as f:
    f.write("\n".join(ids) + ("\n" if ids else ""))

plan[3] = "[✓] Write miRNA_ID list to requested output text file"
print("\nUpdated plan:")
for i, s in enumerate(plan, 1):
    print(f"{i}. {s}")

print("\nResults:")
print(f"- Input rows (raw): {len(df)}")
print(f"- Rows with numeric Abundance: {len(df2)}")
print(f"- Top500 rows saved: {len(top500)}")
print(f"- Intermediate files:")
print(f"  - {raw_head_path}")
print(f"  - {top500_path}")
print(f"  - {top500_ids_path}")
print(f"- Final output file:")
print(f"  - {out_txt}")

# Print first few IDs as a quick check
print("\nFirst 10 miRNA_IDs:")
print("\n".join(ids[:10]))
</execute>
<observation>Research log: Top 500 abundant miRNAs from circulating_miRNome_abundance.csv

Plan:
1. [ ] Load input CSV and validate required columns
2. [ ] Sort by Abundance (desc) and select top 500
3. [ ] Save intermediate tables to tmp directory
4. [ ] Write miRNA_ID list to requested output text file

Updated plan:
1. [✓] Load input CSV and validate required columns
2. [ ] Sort by Abundance (desc) and select top 500
3. [ ] Save intermediate tables to tmp directory
4. [ ] Write miRNA_ID list to requested output text file

Updated plan:
1. [✓] Load input CSV and validate required columns
2. [✓] Sort by Abundance (desc) and select top 500
3. [ ] Save intermediate tables to tmp directory
4. [ ] Write miRNA_ID list to requested output text file

Updated plan:
1. [✓] Load input CSV and validate required columns
2. [✓] Sort by Abundance (desc) and select top 500
3. [✓] Save intermediate tables to tmp directory
4. [ ] Write miRNA_ID list to requested output text file

Updated plan:
1. [✓] Load input CSV and validate required columns
2. [✓] Sort by Abundance (desc) and select top 500
3. [✓] Save intermediate tables to tmp directory
4. [✓] Write miRNA_ID list to requested output text file

Results:
- Input rows (raw): 2000
- Rows with numeric Abundance: 2000
- Top500 rows saved: 500
- Intermediate files:
  - /root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate/input_head.csv
  - /root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate/top500_by_abundance.csv
  - /root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate/top500_miRNA_IDs.txt
- Final output file:
  - /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/cancermirnome_annotate.txt

First 10 miRNA_IDs:
hsa-miR-266b
hsa-miR-733a
hsa-miR-978a
hsa-miR-528a
hsa-miR-605b
hsa-miR-424b
hsa-miR-864b
hsa-miR-267a
hsa-miR-957a
hsa-miR-667b
</observation>
<solution>
Top 500 miRNA_IDs (by descending `Abundance`) were extracted from `benchmark/dataset/CancerMIRNome/circulating_miRNome_abundance.csv` and saved to:

- Final output: `/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.2/cancermirnome_annotate.txt`

Intermediate files saved to:

- `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate/input_head.csv`
- `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate/top500_by_abundance.csv`
- `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.2/cancermirnome_annotate/top500_miRNA_IDs.txt`
</solution>