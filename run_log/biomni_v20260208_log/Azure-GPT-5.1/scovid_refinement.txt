Load the NCBI GEO single-cell RNA-seq dataset GSE182298 located at `benchmark/dataset/SCovid/GSE182298`.'

Perform Quality Control (QC) filtering with the following strict criteria:

Filter out cells that have fewer than 200 detected genes.

Filter out genes that are detected in fewer than 3 cells.

Calculate the percentage of mitochondrial genes (genes starting with prefix "MT-") for each cell.

Apply the tissue-specific mitochondrial filtering rule: If the input tissue is Liver, remove cells with a mitochondrial gene proportion > 50%. (Note: For non-liver tissues, the threshold would be > 20%).

Save the list of remaining valid cell barcodes to a CSV file named /root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.1/qc_passed_barcodes.csv (single column, no header).

All temp data should be save in `/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.1/scovid_refinement`.

Output Format (For Reference)
```
<GSMID1>_barcode1
<GSMID2>_barcode2
...

<execute>
import os
import scanpy as sc
import pandas as pd

print("Step 0: Initialize plan and environment\n")

plan = [
    "[ ] 1. Locate and inspect the GSE182298 dataset under benchmark/dataset/SCovid/GSE182298",
    "[ ] 2. Load the single-cell expression data into an AnnData object",
    "[ ] 3. Apply cell-level QC: filter cells with <200 detected genes and compute mitochondrial percentage",
    "[ ] 4. Apply gene-level QC: filter genes detected in <3 cells",
    "[ ] 5. Apply liver-specific mitochondrial filter (remove cells with MT% > 50%)",
    "[ ] 6. Construct GSMID_barcode identifiers for remaining cells and save to the required CSV path"
]
print("Initial plan:")
for item in plan:
    print(item)

# Helper to update and print plan
def update_plan(step_index, status, reason=None):
    global plan
    prefix_old = plan[step_index][:3]
    if status == "done":
        plan[step_index] = plan[step_index].replace("[ ]", "[✓]", 1)
    elif status == "fail":
        plan[step_index] = plan[step_index].replace("[ ]", "[✗]", 1)
        if reason:
            plan[step_index] += f" ({reason})"
    print("\nUpdated plan:")
    for item in plan:
        print(item)
    print()

# =============================================================================
# 1. Locate and inspect the dataset
# =============================================================================
print("\nStep 1: Locate and inspect the GSE182298 dataset directory\n")

base_dir = "./operation_env/database_lake/benchmark/dataset/SCovid/GSE182298"
print(f"Expected dataset directory: {base_dir}")

if not os.path.exists(base_dir):
    update_plan(0, "fail", f"Directory not found: {base_dir}")
    raise FileNotFoundError(f"Dataset directory not found: {base_dir}")

# List contents
for root, dirs, files in os.walk(base_dir):
    print(f"\nDirectory: {root}")
    for d in dirs:
        print(f"  [D] {d}")
    for f in files:
        print(f"  [F] {f}")
    # Only show top level and immediate children to avoid flooding
    break

update_plan(0, "done")

# Heuristic: identify count matrix file(s)
# Common patterns: .h5ad, matrix.mtx + barcodes.tsv + genes.tsv/features.tsv, or .h5 (10x)
print("Searching for possible expression data files...\n")
data_files = []
for root, dirs, files in os.walk(base_dir):
    for f in files:
        if f.endswith((".h5ad", ".h5", ".mtx", ".mtx.gz", ".loom")) or "matrix" in f.lower():
            data_files.append(os.path.join(root, f))

print("Candidate data files:")
for df in data_files:
    print("  ", df)

# =============================================================================
# 2. Load the single-cell expression data
# =============================================================================
print("\nStep 2: Load the single-cell expression data into AnnData\n")

adata = None

# Priority: .h5ad > 10x .h5 > mtx
h5ad_files = [f for f in data_files if f.endswith(".h5ad")]
h5_files = [f for f in data_files if f.endswith(".h5")]
mtx_files = [f for f in data_files if f.endswith(".mtx") or f.endswith(".mtx.gz")]

if h5ad_files:
    data_path = h5ad_files[0]
    print(f"Loading AnnData from .h5ad: {data_path}")
    adata = sc.read_h5ad(data_path)
elif h5_files:
    # assume 10x h5
    data_path = h5_files[0]
    print(f"Loading 10x data from .h5: {data_path}")
    adata = sc.read_10x_h5(data_path)
elif mtx_files:
    # try 10x mtx structure
    data_path = mtx_files[0]
    print(f"Loading 10x data from matrix.mtx: {data_path}")
    # 10x directory is the parent of matrix.mtx
    tenx_dir = os.path.dirname(data_path)
    adata = sc.read_10x_mtx(tenx_dir, var_names="gene_symbols", cache=False)
else:
    update_plan(1, "fail", "No recognizable expression matrix file found")
    raise RuntimeError("Could not identify expression matrix for GSE182298")

print("\nLoaded AnnData object:")
print(adata)
print("Shape (cells x genes):", adata.n_obs, "x", adata.n_vars)

# Inspect basic metadata
print("\nObservation (cell) metadata columns:", list(adata.obs.columns))
print("Variable (gene) metadata columns:", list(adata.var.columns))

update_plan(1, "done")

# =============================================================================
# 3. Cell-level QC: n_genes and mitochondrial percentage
# =============================================================================
print("\nStep 3: Cell-level QC: filter cells with <200 genes and compute mitochondrial percentage\n")

# Ensure gene names are present
if "gene_symbols" in adata.var.columns:
    gene_names = adata.var["gene_symbols"]
elif "gene" in adata.var.columns:
    gene_names = adata.var["gene"]
else:
    gene_names = adata.var_names

adata.var["gene_symbols_used"] = gene_names

# Identify mitochondrial genes: prefix "MT-"
mt_mask = adata.var["gene_symbols_used"].astype(str).str.upper().str.startswith("MT-")
adata.var["mt"] = mt_mask

print(f"Number of mitochondrial genes detected: {mt_mask.sum()}")

# Calculate QC metrics
sc.pp.calculate_qc_metrics(
    adata,
    qc_vars=["mt"],
    inplace=True
)

print("QC metrics keys in adata.obs:")
for k in adata.obs.columns:
    if "n_genes" in k or "mt" in k or "n_counts" in k:
        print("  ", k)

# Store relevant QC metrics with standard names if needed
if "total_counts" in adata.obs.columns:
    adata.obs["n_counts"] = adata.obs["total_counts"]

if "n_genes_by_counts" in adata.obs.columns:
    adata.obs["n_genes"] = adata.obs["n_genes_by_counts"]

if "pct_counts_mt" in adata.obs.columns:
    adata.obs["pct_mt"] = adata.obs["pct_counts_mt"]
else:
    # calculate manually if needed
    if "mt" in adata.var.columns:
        mt_counts = adata[:, adata.var["mt"]].X.sum(axis=1)
        total_counts = adata.X.sum(axis=1)
        # handle sparse matrices
        import numpy as np
        mt_counts = np.array(mt_counts).flatten()
        total_counts = np.array(total_counts).flatten()
        adata.obs["pct_mt"] = (mt_counts / total_counts) * 100

# Filter cells with <200 detected genes
print("\nNumber of cells before n_genes filter:", adata.n_obs)
cell_filter = adata.obs["n_genes"] >= 200
adata = adata[cell_filter].copy()
print("Number of cells after n_genes >= 200 filter:", adata.n_obs)

update_plan(2, "done")

# =============================================================================
# 4. Gene-level QC: remove genes detected in <3 cells
# =============================================================================
print("\nStep 4: Gene-level QC: filter genes detected in fewer than 3 cells\n")

# sc.pp.filter_genes uses n_cells entry
sc.pp.filter_genes(adata, min_cells=3)

print("Number of genes after min_cells >= 3 filter:", adata.n_vars)
update_plan(3, "done")

# =============================================================================
# 5. Liver-specific mitochondrial filter: pct_mt > 50%
# =============================================================================
print("\nStep 5: Apply liver-specific mitochondrial filter (pct_mt > 50%)\n")

# Tissue is specified as Liver in the instructions, so threshold = 50%
mt_threshold = 50.0
print(f"Using mitochondrial percentage threshold for Liver: {mt_threshold}%")

if "pct_mt" not in adata.obs.columns:
    # If for some reason pct_mt missing, try pct_counts_mt
    if "pct_counts_mt" in adata.obs.columns:
        adata.obs["pct_mt"] = adata.obs["pct_counts_mt"]
    else:
        raise RuntimeError("Mitochondrial percentage (pct_mt) is not available in adata.obs")

print("Number of cells before mitochondrial filter:", adata.n_obs)
mt_filter = adata.obs["pct_mt"] <= mt_threshold
adata = adata[mt_filter].copy()
print("Number of cells after mitochondrial filter:", adata.n_obs)

update_plan(4, "done")

# =============================================================================
# 6. Construct GSMID_barcode identifiers and save to CSV
# =============================================================================
print("\nStep 6: Construct GSMID_barcode identifiers and save\n")

# We need format: <GSMID>_barcode, where GSMID is per-GEO-sample ID.
# Approaches:
# 1) If GSM ID present as a column in adata.obs (e.g., 'gsm', 'GSM', 'sample', etc.) use that.
# 2) If not, try to infer from obs_names if they look like "GSMxxxxxx_barcode".
# 3) If no GSM, fall back to whatever per-cell sample ID exists, but maintain format.

gsm_col = None
candidate_cols = [c for c in adata.obs.columns if "gsm" in c.lower() or "GSM" in c]
print("Candidate GSM-related columns in adata.obs:", candidate_cols)

if candidate_cols:
    gsm_col = candidate_cols[0]
    print(f"Using GSM column: {gsm_col}")
    gsm_ids = adata.obs[gsm_col].astype(str)
else:
    # Try to parse from obs_names
    obs_names = pd.Index(adata.obs_names.astype(str))
    # Check pattern: first token "GSM" followed by digits then underscore
    # e.g., GSM182298_ABCDEF
    if obs_names.str.startswith("GSM").any():
        # split by first underscore
        gsm_ids = obs_names.str.split("_", n=1).str[0]
        print("Inferred GSM IDs from obs_names.")
    else:
        # if no GSM ID information, we will treat a common pseudo-sample ID
        gsm_ids = pd.Series(["GSE182298"] * adata.n_obs, index=adata.obs_names)
        print("No GSM ID found; using 'GSE182298' as sample prefix for all cells.")

# Determine barcode part
obs_names = pd.Index(adata.obs_names.astype(str))
if obs_names.str.contains("_").all():
    barcodes = obs_names.str.split("_", n=1).str[-1]
else:
    # If obs_names are already barcodes, use them directly
    barcodes = obs_names

# Make sure gsm_ids index aligns with adata.obs_names
if isinstance(gsm_ids, pd.Series):
    gsm_ids = gsm_ids.reindex(adata.obs_names)
else:
    gsm_ids = pd.Series(gsm_ids, index=adata.obs_names)

combined_ids = gsm_ids.astype(str) + "_" + barcodes.astype(str)

print("Example combined IDs:")
print(combined_ids.head())

# Prepare output directory and file
tmp_dir = "/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.1/scovid_refinement"
os.makedirs(tmp_dir, exist_ok=True)

output_path = "/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.1/qc_passed_barcodes.csv"
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Single column, no header
combined_ids.to_frame(name="barcode").to_csv(output_path, index=False, header=False)

print(f"\nSaved QC-passed barcodes to: {output_path}")
print(f"Total number of QC-passed cells: {combined_ids.shape[0]}")

update_plan(5, "done")

print("\nFinal plan status:")
for item in plan:
    print(item)
</execute>
<observation>ModuleNotFoundError("No module named 'scanpy'")</observation>
<execute>
import os
import sys
import pandas as pd
import numpy as np
from scipy import io as spio
from scipy import sparse

print("Step 0: Initialize plan and environment\n")

plan = [
    "[ ] 1. Locate and inspect the GSE182298 dataset under benchmark/dataset/SCovid/GSE182298",
    "[ ] 2. Load the single-cell expression data into a suitable in-memory structure (no scanpy)",
    "[ ] 3. Apply cell-level QC: filter cells with <200 detected genes and compute mitochondrial percentage",
    "[ ] 4. Apply gene-level QC: filter genes detected in <3 cells",
    "[ ] 5. Apply liver-specific mitochondrial filter (remove cells with MT% > 50%)",
    "[ ] 6. Construct GSMID_barcode identifiers for remaining cells and save to the required CSV path"
]
print("Initial plan:")
for item in plan:
    print(item)

def update_plan(step_index, status, reason=None):
    global plan
    if status == "done":
        plan[step_index] = plan[step_index].replace("[ ]", "[✓]", 1)
    elif status == "fail":
        plan[step_index] = plan[step_index].replace("[ ]", "[✗]", 1)
        if reason:
            plan[step_index] += f" ({reason})"
    print("\nUpdated plan:")
    for item in plan:
        print(item)
    print()

# =============================================================================
# 1. Locate and inspect the dataset
# =============================================================================
print("\nStep 1: Locate and inspect the GSE182298 dataset directory\n")

base_dir = "./operation_env/database_lake/benchmark/dataset/SCovid/GSE182298"
print(f"Expected dataset directory: {base_dir}")

if not os.path.exists(base_dir):
    update_plan(0, "fail", f"Directory not found: {base_dir}")
    raise FileNotFoundError(f"Dataset directory not found: {base_dir}")

for root, dirs, files in os.walk(base_dir):
    print(f"\nDirectory: {root}")
    for d in dirs:
        print(f"  [D] {d}")
    for f in files:
        print(f"  [F] {f}")
    break

update_plan(0, "done")

print("Searching for potential 10x/MTX files...\n")
candidate_mtx = []
for root, dirs, files in os.walk(base_dir):
    for f in files:
        if f.lower().endswith(".mtx") or f.lower().endswith(".mtx.gz"):
            candidate_mtx.append(os.path.join(root, f))

print("Candidate matrix files:")
for p in candidate_mtx:
    print("  ", p)

# =============================================================================
# 2. Load expression data (assume 10x-style MTX)
# =============================================================================
print("\nStep 2: Load the single-cell expression data (without scanpy)\n")

if not candidate_mtx:
    update_plan(1, "fail", "No .mtx matrix file found")
    raise RuntimeError("No matrix.mtx found under GSE182298")

# Heuristic: choose 'matrix.mtx' or the first candidate
mtx_path = None
for p in candidate_mtx:
    if os.path.basename(p).lower().startswith("matrix"):
        mtx_path = p
        break
if mtx_path is None:
    mtx_path = candidate_mtx[0]

tenx_dir = os.path.dirname(mtx_path)
print(f"Using 10x directory: {tenx_dir}")
print(f"Matrix file: {mtx_path}")

# Identify genes/features and barcodes files
genes_path = None
features_path = None
barcodes_path = None

for f in os.listdir(tenx_dir):
    fn = f.lower()
    fp = os.path.join(tenx_dir, f)
    if "genes" in fn and fn.endswith((".tsv", ".tsv.gz", ".txt")):
        genes_path = fp
    elif "features" in fn and fn.endswith((".tsv", ".tsv.gz", ".txt")):
        features_path = fp
    elif "barcodes" in fn and fn.endswith((".tsv", ".tsv.gz", ".txt")):
        barcodes_path = fp

print("Detected associated files:")
print("  genes   :", genes_path)
print("  features:", features_path)
print("  barcodes:", barcodes_path)

if barcodes_path is None:
    update_plan(1, "fail", "No barcodes file found in 10x directory")
    raise RuntimeError("No barcodes.tsv/features.tsv found for GSE182298")

# Load barcodes (cell barcodes)
if barcodes_path.endswith(".gz"):
    barcodes = pd.read_csv(barcodes_path, header=None, sep="\t", compression="gzip")[0].astype(str).values
else:
    barcodes = pd.read_csv(barcodes_path, header=None, sep="\t")[0].astype(str).values
n_cells = len(barcodes)
print(f"Loaded {n_cells} barcodes")

# Load genes/features to get gene symbols
gene_symbols = None

if features_path is not None:
    if features_path.endswith(".gz"):
        feats = pd.read_csv(features_path, header=None, sep="\t", compression="gzip")
    else:
        feats = pd.read_csv(features_path, header=None, sep="\t")
    # For 10x v3, columns: id, name, type
    if feats.shape[1] >= 2:
        gene_symbols = feats.iloc[:, 1].astype(str).values
    else:
        gene_symbols = feats.iloc[:, 0].astype(str).values
    print(f"Loaded {len(gene_symbols)} feature names from features file")
elif genes_path is not None:
    if genes_path.endswith(".gz"):
        genes_df = pd.read_csv(genes_path, header=None, sep="\t", compression="gzip")
    else:
        genes_df = pd.read_csv(genes_path, header=None, sep="\t")
    if genes_df.shape[1] >= 2:
        gene_symbols = genes_df.iloc[:, 1].astype(str).values
    else:
        gene_symbols = genes_df.iloc[:, 0].astype(str).values
    print(f"Loaded {len(gene_symbols)} gene names from genes file")
else:
    update_plan(1, "fail", "No genes/features file found")
    raise RuntimeError("No genes/features file found for GSE182298")

# Load the sparse matrix
print("Loading sparse count matrix (this may take a moment)...")
X = spio.mmread(mtx_path).tocsr()
print("Original matrix shape (genes x cells):", X.shape)

# Ensure orientation is genes x cells
if X.shape[1] == n_cells:
    pass  # assumed correct
elif X.shape[0] == n_cells:
    X = X.T.tocsr()
    print("Transposed matrix to genes x cells. New shape:", X.shape)
else:
    print("Warning: matrix dimension does not match number of barcodes; proceeding with shape:", X.shape)

if X.shape[0] != len(gene_symbols):
    print("Warning: number of rows in matrix != number of gene symbols; using min length")
    min_len = min(X.shape[0], len(gene_symbols))
    X = X[:min_len, :]
    gene_symbols = gene_symbols[:min_len]

print("Final matrix shape used (genes x cells):", X.shape)

update_plan(1, "done")

# =============================================================================
# 3. Cell-level QC: n_genes and mitochondrial percentage
# =============================================================================
print("\nStep 3: Cell-level QC: filter cells with <200 detected genes and compute mitochondrial percentage\n")

# n_genes per cell: count of non-zero genes
print("Computing number of detected genes per cell...")
n_genes_per_cell = np.diff(X.indptr)  # since matrix is csr with genes x cells, need per column -> we transposed
# Wait: X is genes x cells in CSR; CSR is fast per row, not per column. Above gives nnz per row (gene).
# We actually need per column (cell). So convert to CSC for this computation.
X_csc = X.tocsc()
n_genes_per_cell = np.diff(X_csc.indptr)
print("Example n_genes_per_cell:", n_genes_per_cell[:5])

# Total counts per cell
print("Computing total counts per cell...")
total_counts_per_cell = np.array(X_csc.sum(axis=0)).ravel()
print("Example total_counts_per_cell:", total_counts_per_cell[:5])

# Mitochondrial genes mask (MT- prefix, case-insensitive)
gene_symbols_upper = np.array([g.upper() for g in gene_symbols])
mt_mask = np.array([g.startswith("MT-") for g in gene_symbols_upper])
n_mt_genes = mt_mask.sum()
print(f"Number of mitochondrial genes detected: {n_mt_genes}")

if n_mt_genes > 0:
    X_mt = X[mt_mask, :]  # genes x cells for mt genes
    X_mt_csc = X_mt.tocsc()
    mt_counts_per_cell = np.array(X_mt_csc.sum(axis=0)).ravel()
else:
    mt_counts_per_cell = np.zeros(X.shape[1], dtype=float)

# mitochondrial percentage per cell
with np.errstate(divide="ignore", invalid="ignore"):
    pct_mt = np.where(total_counts_per_cell > 0,
                      (mt_counts_per_cell / total_counts_per_cell) * 100.0,
                      0.0)

print("Example pct_mt:", pct_mt[:5])

# Filter cells with <200 detected genes
print("\nNumber of cells before n_genes filter:", X.shape[1])
cell_filter_n_genes = n_genes_per_cell >= 200
print("Cells passing n_genes >= 200:", cell_filter_n_genes.sum())

X = X[:, cell_filter_n_genes]
X_csc = X.tocsc()
pct_mt = pct_mt[cell_filter_n_genes]
total_counts_per_cell = total_counts_per_cell[cell_filter_n_genes]
n_genes_per_cell = n_genes_per_cell[cell_filter_n_genes]
barcodes = barcodes[cell_filter_n_genes]

print("Number of cells after n_genes filter:", X.shape[1])
update_plan(2, "done")

# =============================================================================
# 4. Gene-level QC: genes detected in >=3 cells
# =============================================================================
print("\nStep 4: Gene-level QC: filter genes detected in fewer than 3 cells\n")

# Genes x cells in CSR; per-gene nnz is fast in CSR
n_cells_per_gene = np.diff(X.indptr)
print("Example n_cells_per_gene:", n_cells_per_gene[:5])

gene_filter_min_cells = n_cells_per_gene >= 3
print("Genes passing min_cells >= 3:", gene_filter_min_cells.sum(), "of", X.shape[0])

X = X[gene_filter_min_cells, :]
gene_symbols = gene_symbols[gene_filter_min_cells]
mt_mask = mt_mask[gene_filter_min_cells]

print("Matrix shape after gene filter (genes x cells):", X.shape)
update_plan(3, "done")

# =============================================================================
# 5. Liver-specific mitochondrial filter: pct_mt <= 50%
# =============================================================================
print("\nStep 5: Apply liver-specific mitochondrial filter (pct_mt > 50%)\n")

mt_threshold = 50.0
print(f"Using mitochondrial percentage threshold for Liver: {mt_threshold}%")
print("Number of cells before mitochondrial filter:", X.shape[1])

cell_filter_mt = pct_mt <= mt_threshold
print("Cells passing mt filter:", cell_filter_mt.sum())

X = X[:, cell_filter_mt]
barcodes = barcodes[cell_filter_mt]
pct_mt = pct_mt[cell_filter_mt]
n_genes_per_cell = n_genes_per_cell[cell_filter_mt]
total_counts_per_cell = total_counts_per_cell[cell_filter_mt]

print("Number of cells after mitochondrial filter:", X.shape[1])
update_plan(4, "done")

# =============================================================================
# 6. Construct GSMID_barcode identifiers and save
# =============================================================================
print("\nStep 6: Construct GSMID_barcode identifiers and save\n")

# We do not have per-GSM metadata; the instruction's format is <GSMID>_barcode.
# Without GSM info in these raw 10x files, we use the GSE accession as a proxy:
gsm_prefix = "GSE182298"

combined_ids = pd.Series([f"{gsm_prefix}_{bc}" for bc in barcodes],
                         index=None, name="id")
print("Example combined IDs:")
print(combined_ids.head())

tmp_dir = "/root/biodatalab/log/biomni_v20260209_tmp/OpenAI/Azure-GPT-5.1/scovid_refinement"
os.makedirs(tmp_dir, exist_ok=True)

output_path = "/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.1/qc_passed_barcodes.csv"
os.makedirs(os.path.dirname(output_path), exist_ok=True)

combined_ids.to_csv(output_path, index=False, header=False)

print(f"\nSaved QC-passed barcodes to: {output_path}")
print(f"Total number of QC-passed cells: {combined_ids.shape[0]}")

update_plan(5, "done")

print("\nFinal plan status:")
for item in plan:
    print(item)
</execute>
<observation>FileNotFoundError('Dataset directory not found: ./operation_env/database_lake/benchmark/dataset/SCovid/GSE182298')</observation>
<solution>
1. [✗] Locate and inspect the GSE182298 dataset under benchmark/dataset/SCovid/GSE182298 (failed because the directory `./operation_env/database_lake/benchmark/dataset/SCovid/GSE182298` does not exist in the current environment)
2. [ ] Load the single-cell expression data into a suitable in-memory structure (no scanpy)
3. [ ] Apply cell-level QC: filter cells with &lt;200 detected genes and compute mitochondrial percentage
4. [ ] Apply gene-level QC: filter genes detected in &lt;3 cells
5. [ ] Apply liver-specific mitochondrial filter (remove cells with MT% &gt; 50%)
6. [ ] Construct GSMID_barcode identifiers for remaining cells and save to the required CSV path

I attempted to access the dataset at the specified path:

`./operation_env/database_lake/benchmark/dataset/SCovid/GSE182298`

but the directory is not present in the current environment, leading to:

`FileNotFoundError('Dataset directory not found: ./operation_env/database_lake/benchmark/dataset/SCovid/GSE182298')`

Because the raw expression matrix and barcodes are unavailable, I cannot perform QC or generate the final list of barcodes.

To proceed, you can:

- Confirm that the dataset is present under the expected path, or  
- Provide the correct path to the GSE182298 single‑cell data (or upload the relevant files, e.g., 10x-style `matrix.mtx`, `barcodes.tsv`, and `features.tsv/genes.tsv`), and I can then re-run the QC steps and write:

`/root/biodatalab/log/biomni_v20260209_pred_results/OpenAI/Azure-GPT-5.1/qc_passed_barcodes.csv`

in the requested format:

`<GSMID>_barcode`

Once the dataset is accessible in this environment, I will:
- Load it,
- Apply the specified filters (cells with ≥200 genes, genes in ≥3 cells, liver threshold mt% ≤50), and
- Save the QC-passed barcodes to the exact path you requested. </solution>